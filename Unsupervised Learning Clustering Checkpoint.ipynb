{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18a4ff6-acd2-4e58-a8de-0661e6cc57ab",
   "metadata": {},
   "source": [
    "# Credit Card Dataset for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54032fc-b098-485b-8c7d-2b248aea229d",
   "metadata": {},
   "source": [
    "In this project, we'll use the 'Credit Card Dataset for Clustering' provided by Kaggle.\n",
    "\n",
    "\n",
    "Dataset description : This dataset was derived and simplified for learning purposes. It includes usage behaviour of about 9000 active credit card holders during 6 months period. This case requires to develop a customer segmentation to define marketing strategy.\n",
    "\n",
    "➡️ Dataset link \n",
    "\n",
    "https://i.imgur.com/gAT5gVg.jpg\n",
    "\n",
    "- **Columns explanation :** \n",
    "\n",
    "- CUST_ID: Identification of Credit Card holder (Categorical)\n",
    "- BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
    "- PURCHASES: Amount of purchases made from account \n",
    "- CASH_ADVANCE: Cash in advance given by the user\n",
    "- CREDIT_LIMIT: Limit of Credit Card for user \n",
    "- PAYMENTS: Amount of Payment done by user \n",
    "\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import you data and perform basic data2.  exploration phase\n",
    "- Perform the necessary data preparation steps ( Corrupted and missing values handling, a encoding, outl3. iers handling ... )\n",
    "- Perform hierarchical clustering to identify the inherent groupings within your data. Then, plot the clusters. (use only 2 features. For example, try to cluster the customer base with respect to 'PURCHASES'4.  and 'credit limit')\n",
    "- Perform partitional clustering using the K-means algorithm. Th5. en, plot the clusters\n",
    "- Find the best k value and pl6. ot the clusters again.\n",
    "- Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97e54db-d1f8-4347-87d8-ffaea0df2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f50f34-f46d-48be-b41a-949403eb10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.cluster import AgglomerativeClustering  \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451c2940-78cc-4cfd-bce7-51eca3f1acb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Credit_card_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCredit_card_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Credit_card_dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Credit_card_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7820f8-086a-40aa-b632-ca0429523845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295e98-1285-4a77-8b8d-da6eabf46289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d31aae-f4d1-48e5-b1ea-5b49a21a576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb855f8-9208-4ded-8cc8-6e8811267fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2730e-58d0-48f8-b3e5-d90abf80112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d3a36-9f8e-4242-a2a3-0d4eb8aefd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244b105-4a5d-4eb5-9d0d-ccc039d09210",
   "metadata": {},
   "source": [
    "There are no categorical columns to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ab945-3bf8-47e1-a52b-3b383482524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant features\n",
    "X = df[[\"PURCHASES\", \"CREDIT_LIMIT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28a4fa-d4e1-49ce-995b-17db867a352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecdaa5-377a-498f-915d-f207c743c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(X_scaled, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032278aa-e335-4895-849e-6837da965581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure with a specific size for the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "\n",
    "# Add a title to the plot to describe it as a dendrogram for agglomerative clustering\n",
    "plt.title('Dendrogram for Agglomerative Clustering')\n",
    "\n",
    "# Label the x-axis as 'Data Points' since the horizontal axis represents the individual data points or clusters\n",
    "plt.xlabel('Data Points')\n",
    "\n",
    "# Label the y-axis as 'Euclidean Distance' because the vertical axis represents the distance between merged clusters\n",
    "plt.ylabel('Euclidean Distance')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29291122-a3d9-4754-8014-6024db3b7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters=6, metric='euclidean', linkage='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c88af-46f2-440f-a49e-d65dd467fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = agglom.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2099c-9abc-4e01-a744-26c272b2e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59adc2d-bc0b-4d16-ace7-b44b35372bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters using a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['PURCHASES'], y=df['CREDIT_LIMIT'], hue=df['Cluster'], palette='Set1')\n",
    "plt.title('Credit Card holder Segmentation based on Purchases and Credit Limit (Agglomerative Clustering)')\n",
    "plt.xlabel('Purchases')\n",
    "plt.ylabel('Credit Limit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c6fbe-315f-43f1-812a-de92b54b24fa",
   "metadata": {},
   "source": [
    "### K means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32e5e6-c7f6-46cb-9bbe-9f9027558400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d737b4-4b27-42bd-b1c3-a3e3850a2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Credit_card_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c6554-49bb-4180-bfc4-552036a0c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9b5df-fa45-4e27-99a0-2b1cadc1f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed18085-af16-4cd9-8889-b70fe284dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1ae53-d22d-404c-89d5-563dddbcadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f4152-d435-422a-b3e9-d1369342fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9e9d1-b0f2-4a5d-9c6b-d7d94dbe601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant features\n",
    "X = df[[\"PURCHASES\", \"CREDIT_LIMIT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb692846-ab11-4643-b11a-0655a034be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f1212-134d-4321-b8dc-ce0a63eef003",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []  # List to store the inertia values for each number of clusters\n",
    "\n",
    "for i in range(1, 11):  # Loop over cluster numbers from 1 to 10\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)  # Initialize KMeans with the current number of clusters (i)\n",
    "    kmeans.fit(X_scaled)  # Fit the KMeans model on the standardized data\n",
    "    inertia.append(kmeans.inertia_)  # Append the inertia (sum of squared distances) to the list\n",
    "\n",
    "# Plot the Elbow curve\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better visibility\n",
    "plt.plot(range(1, 11), inertia, 'ro-')  # Plot the number of clusters against inertia with red markers and lines\n",
    "# 'r': Specifies the color of the plot, in this case, red (r stands for red).\n",
    "# 'o': Specifies the marker style, which in this case is a circle (o).\n",
    "# '-': Specifies the line style, which in this case is a solid line (-).\n",
    "\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')  # Add a title to the plot\n",
    "plt.xlabel('Number of Clusters')  # Label the x-axis as 'Number of Clusters'\n",
    "plt.ylabel('Inertia')  # Label the y-axis as 'Inertia' (within-cluster sum of squares)\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc266971-3c4a-478e-bf64-6adfc6caaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means with 5 clusters\n",
    "kmeans = KMeans(n_clusters=6, random_state=42) \n",
    "kmeans.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ae776-5eb9-49f5-a881-d4c94da94f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68763b8c-af21-4762-bef9-c39e26160e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters using a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['PURCHASES'], y=df['CREDIT_LIMIT'], hue=df['Cluster'], palette='Set1')\n",
    "plt.title('Credit Card holder Segmentation based on Purchases and Credit Limit (Agglomerative Clustering)')\n",
    "plt.xlabel('Purchases')\n",
    "plt.ylabel('Credit Limit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89966db-034c-4747-8061-135246f19d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
